{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "seed = 782\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Train images: (30000, 784)\n",
      "Shape Labels: (30000)\n",
      "Shape Train Images: (12000, 784)\n",
      "Shape Labels: (12000)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"digit_train.csv\")\n",
    "train = df.as_matrix()\n",
    "\n",
    "\n",
    "\n",
    "train_y = train[:30000,0].astype('int8')\n",
    "train_x = train[:30000,1:].astype('float64')\n",
    "\n",
    "test_y = train[30000:,0].astype('int8')\n",
    "test_x = train[30000:,1:].astype('float64')\n",
    "\n",
    "print(\"Shape Train images: (%d, %d)\" %train_x.shape)\n",
    "print(\"Shape Labels: (%d)\" % train_y.shape)\n",
    "print(\"Shape Train Images: (%d, %d)\"% test_x.shape)\n",
    "print(\"Shape Labels: (%d)\" % test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_image(image, shape, label=\"\", cmp=None):\n",
    "    img = np.reshape(image, shape)\n",
    "    plt.imshow(img, cmap=cmp, interpolation='none')\n",
    "    plt.title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB5Ii/EBShB9I6r8lodzlS/+THAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c7dec18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(train_x[6], (28,28), cmp=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAIqCAYAAADBx0cIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl78AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bc8b048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,10))\n",
    "\n",
    "y,x= 5, 10\n",
    "for i in range(0, (x*y)):\n",
    "    plt.subplot(y,x,i+1)\n",
    "    ni = np.random.randint(0,train_x.shape[0],1)[0]\n",
    "    show_image(train_x[ni],(28,28), train_y[ni], cmp=\"gray\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_example_per_digit(examples):\n",
    "    bins = [0,1,2,3,4,5,6,7,8,9,10]    \n",
    "    plt.hist(examples, bins, label=\"counts\")\n",
    "    plt.legend()\n",
    "    plt.xticks(bins)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ba14d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_example_per_digit(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 2, 3, 0], dtype=int8)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=[30,], max_iter=10, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.45132812\n",
      "Iteration 2, loss = 0.22552462\n",
      "Iteration 3, loss = 0.18022069\n",
      "Iteration 4, loss = 0.15208298\n",
      "Iteration 5, loss = 0.13651977\n",
      "Iteration 6, loss = 0.11909440\n",
      "Iteration 7, loss = 0.10917186\n",
      "Iteration 8, loss = 0.10096336\n",
      "Iteration 9, loss = 0.09140311\n",
      "Iteration 10, loss = 0.08511767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=[30], learning_rate='constant',\n",
       "       learning_rate_init=0.1, max_iter=10, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='sgd', tol=0.0001, validation_fraction=0.1, verbose=10,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sc = preprocessing.StandardScaler.fit(train_x)\n",
    "#train_x_std = sc.fit_transform(train_x)\n",
    "#test_x_std = sc.fit_transform(test_x)\n",
    "\n",
    "train_x = train_x/255.\n",
    "test_x = test_x/255.\n",
    "\n",
    "mlp.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97596666666666665"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95466666666666666"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.StandardScaler.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Illegal argument(s) to subplot: (4, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-f9a78069c1e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     ax.matshow(coef.reshape(28,28), cmap=plt.cm.gray, vmin=.5*vmin, \n\u001b[1;32m      5\u001b[0m               vmax=.5*vmax)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msubplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m     \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m     \u001b[0mbyebye\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1068\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_subplots.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;31m# num - 1 for converting from MATLAB to python indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Illegal argument(s) to subplot: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Illegal argument(s) to subplot: (4, 4)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bb519b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplot(4,4)\n",
    "vmin, vmax, mlp.coefs_[0].min(), mlp.coefs_[0].max()\n",
    "for coef, ax in zip(mlp.coefs_[0].T, mlp.coefs_[0].max()):\n",
    "    ax.matshow(coef.reshape(28,28), cmap=plt.cm.gray, vmin=.5*vmin, \n",
    "              vmax=.5*vmax)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\"hidden_layer_sizes\": [(40,),(35,)],\n",
    "              \"learning_rate_init\": [0.1, 0.2],\n",
    "              \"tol\": [1e-3,1e-4],\n",
    "              \"epsilon\": [1e-3, 1e-7, 1e-8, 1e-9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = GridSearchCV(mlp, param_grid = param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.53695208\n",
      "Iteration 2, loss = 0.25825986\n",
      "Iteration 3, loss = 0.20772753\n",
      "Iteration 4, loss = 0.17728622\n",
      "Iteration 5, loss = 0.15360470\n",
      "Iteration 6, loss = 0.13947020\n",
      "Iteration 7, loss = 0.12655701\n",
      "Iteration 8, loss = 0.11772564\n",
      "Iteration 9, loss = 0.10486691\n",
      "Iteration 10, loss = 0.09623685\n",
      "Iteration 1, loss = 0.53281002\n",
      "Iteration 2, loss = 0.25866251\n",
      "Iteration 3, loss = 0.20826052\n",
      "Iteration 4, loss = 0.17454317\n",
      "Iteration 5, loss = 0.15126524\n",
      "Iteration 6, loss = 0.13344943\n",
      "Iteration 7, loss = 0.12083509\n",
      "Iteration 8, loss = 0.10844875\n",
      "Iteration 9, loss = 0.09794414\n",
      "Iteration 10, loss = 0.08692843\n",
      "Iteration 1, loss = 0.53139858\n",
      "Iteration 2, loss = 0.25260228\n",
      "Iteration 3, loss = 0.20332446\n",
      "Iteration 4, loss = 0.26054551\n",
      "Iteration 5, loss = 0.15742678\n",
      "Iteration 6, loss = 0.13507657\n",
      "Iteration 7, loss = 0.11951732\n",
      "Iteration 8, loss = 0.10793472\n",
      "Iteration 9, loss = 0.11183460\n",
      "Iteration 10, loss = 0.08737538\n",
      "Iteration 1, loss = 0.53695208\n",
      "Iteration 2, loss = 0.25825986\n",
      "Iteration 3, loss = 0.20772753\n",
      "Iteration 4, loss = 0.17728622\n",
      "Iteration 5, loss = 0.15360470\n",
      "Iteration 6, loss = 0.13947020\n",
      "Iteration 7, loss = 0.12655701\n",
      "Iteration 8, loss = 0.11772564\n",
      "Iteration 9, loss = 0.10486691\n",
      "Iteration 10, loss = 0.09623685\n",
      "Iteration 1, loss = 0.53281002\n",
      "Iteration 2, loss = 0.25866251\n",
      "Iteration 3, loss = 0.20826052\n",
      "Iteration 4, loss = 0.17454317\n",
      "Iteration 5, loss = 0.15126524\n",
      "Iteration 6, loss = 0.13344943\n",
      "Iteration 7, loss = 0.12083509\n",
      "Iteration 8, loss = 0.10844875\n",
      "Iteration 9, loss = 0.09794414\n",
      "Iteration 10, loss = 0.08692843\n",
      "Iteration 1, loss = 0.53139858\n",
      "Iteration 2, loss = 0.25260228\n",
      "Iteration 3, loss = 0.20332446\n",
      "Iteration 4, loss = 0.26054551\n",
      "Iteration 5, loss = 0.15742678\n",
      "Iteration 6, loss = 0.13507657\n",
      "Iteration 7, loss = 0.11951732\n",
      "Iteration 8, loss = 0.10793472\n",
      "Iteration 9, loss = 0.11183460\n",
      "Iteration 10, loss = 0.08737538\n",
      "Iteration 1, loss = 2.21989565\n",
      "Iteration 2, loss = 2.00487077\n",
      "Iteration 3, loss = 2.01204842\n",
      "Iteration 4, loss = 2.01914811\n",
      "Iteration 5, loss = 1.99818281\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.43467634\n",
      "Iteration 2, loss = 2.29333744\n",
      "Iteration 3, loss = 2.31667779\n",
      "Iteration 4, loss = 2.31396308\n",
      "Iteration 5, loss = 2.31361523\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.13310501\n",
      "Iteration 2, loss = 1.96055013\n",
      "Iteration 3, loss = 1.84948576\n",
      "Iteration 4, loss = 1.84061516\n",
      "Iteration 5, loss = 2.03487782\n",
      "Iteration 6, loss = 2.02805751\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.21989565\n",
      "Iteration 2, loss = 2.00487077\n",
      "Iteration 3, loss = 2.01204842\n",
      "Iteration 4, loss = 2.01914811\n",
      "Iteration 5, loss = 1.99818281\n",
      "Iteration 6, loss = 1.98927647\n",
      "Iteration 7, loss = 1.98560550\n",
      "Iteration 8, loss = 1.98292422\n",
      "Iteration 9, loss = 2.00306895\n",
      "Iteration 10, loss = 1.98352118\n",
      "Iteration 1, loss = 2.43467634\n",
      "Iteration 2, loss = 2.29333744\n",
      "Iteration 3, loss = 2.31667779\n",
      "Iteration 4, loss = 2.31396308\n",
      "Iteration 5, loss = 2.31361523\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.13310501\n",
      "Iteration 2, loss = 1.96055013\n",
      "Iteration 3, loss = 1.84948576\n",
      "Iteration 4, loss = 1.84061516\n",
      "Iteration 5, loss = 2.03487782\n",
      "Iteration 6, loss = 2.02805751\n",
      "Iteration 7, loss = 2.00818991\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.51894432\n",
      "Iteration 2, loss = 0.24614525\n",
      "Iteration 3, loss = 0.19337445\n",
      "Iteration 4, loss = 0.15705643\n",
      "Iteration 5, loss = 0.13010558\n",
      "Iteration 6, loss = 0.11287046\n",
      "Iteration 7, loss = 0.09522054\n",
      "Iteration 8, loss = 0.08346734\n",
      "Iteration 9, loss = 0.07449011\n",
      "Iteration 10, loss = 0.06684617\n",
      "Iteration 1, loss = 0.52261172\n",
      "Iteration 2, loss = 0.24268585\n",
      "Iteration 3, loss = 0.18905108\n",
      "Iteration 4, loss = 0.15554858\n",
      "Iteration 5, loss = 0.13135969\n",
      "Iteration 6, loss = 0.11355115\n",
      "Iteration 7, loss = 0.09644722\n",
      "Iteration 8, loss = 0.08392423\n",
      "Iteration 9, loss = 0.07303382\n",
      "Iteration 10, loss = 0.06393290\n",
      "Iteration 1, loss = 0.52459440\n",
      "Iteration 2, loss = 0.24166603\n",
      "Iteration 3, loss = 0.18620071\n",
      "Iteration 4, loss = 0.15008212\n",
      "Iteration 5, loss = 0.12376611\n",
      "Iteration 6, loss = 0.12078958\n",
      "Iteration 7, loss = 0.09637790\n",
      "Iteration 8, loss = 0.08101470\n",
      "Iteration 9, loss = 0.10801892\n",
      "Iteration 10, loss = 0.11200647\n",
      "Iteration 1, loss = 0.51894432\n",
      "Iteration 2, loss = 0.24614525\n",
      "Iteration 3, loss = 0.19337445\n",
      "Iteration 4, loss = 0.15705643\n",
      "Iteration 5, loss = 0.13010558\n",
      "Iteration 6, loss = 0.11287046\n",
      "Iteration 7, loss = 0.09522054\n",
      "Iteration 8, loss = 0.08346734\n",
      "Iteration 9, loss = 0.07449011\n",
      "Iteration 10, loss = 0.06684617\n",
      "Iteration 1, loss = 0.52261172\n",
      "Iteration 2, loss = 0.24268585\n",
      "Iteration 3, loss = 0.18905108\n",
      "Iteration 4, loss = 0.15554858\n",
      "Iteration 5, loss = 0.13135969\n",
      "Iteration 6, loss = 0.11355115\n",
      "Iteration 7, loss = 0.09644722\n",
      "Iteration 8, loss = 0.08392423\n",
      "Iteration 9, loss = 0.07303382\n",
      "Iteration 10, loss = 0.06393290\n",
      "Iteration 1, loss = 0.52459440\n",
      "Iteration 2, loss = 0.24166603\n",
      "Iteration 3, loss = 0.18620071\n",
      "Iteration 4, loss = 0.15008212\n",
      "Iteration 5, loss = 0.12376611\n",
      "Iteration 6, loss = 0.12078958\n",
      "Iteration 7, loss = 0.09637790\n",
      "Iteration 8, loss = 0.08101470\n",
      "Iteration 9, loss = 0.10801892\n",
      "Iteration 10, loss = 0.11200647\n",
      "Iteration 1, loss = 1.87127182\n",
      "Iteration 2, loss = 1.62047412\n",
      "Iteration 3, loss = 1.81158201\n",
      "Iteration 4, loss = 1.97562672\n",
      "Iteration 5, loss = 1.99099006\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.95757590\n",
      "Iteration 2, loss = 1.86309499\n",
      "Iteration 3, loss = 1.99902641\n",
      "Iteration 4, loss = 1.98304667\n",
      "Iteration 5, loss = 1.92224295\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.15750298\n",
      "Iteration 2, loss = 1.95112950\n",
      "Iteration 3, loss = 2.02214689\n",
      "Iteration 4, loss = 2.00088135\n",
      "Iteration 5, loss = 1.99149022\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.87127182\n",
      "Iteration 2, loss = 1.62047412\n",
      "Iteration 3, loss = 1.81158201\n",
      "Iteration 4, loss = 1.97562672\n",
      "Iteration 5, loss = 1.99099006\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.95757590\n",
      "Iteration 2, loss = 1.86309499\n",
      "Iteration 3, loss = 1.99902641\n",
      "Iteration 4, loss = 1.98304667\n",
      "Iteration 5, loss = 1.92224295\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.15750298\n",
      "Iteration 2, loss = 1.95112950\n",
      "Iteration 3, loss = 2.02214689\n",
      "Iteration 4, loss = 2.00088135\n",
      "Iteration 5, loss = 1.99149022\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.50599556\n",
      "Iteration 2, loss = 0.23863333\n",
      "Iteration 3, loss = 0.18214889\n",
      "Iteration 4, loss = 0.14587668\n",
      "Iteration 5, loss = 0.12118906\n",
      "Iteration 6, loss = 0.10179355\n",
      "Iteration 7, loss = 0.08626492\n",
      "Iteration 8, loss = 0.07634892\n",
      "Iteration 9, loss = 0.06544944\n",
      "Iteration 10, loss = 0.05483956\n",
      "Iteration 1, loss = 0.49776709\n",
      "Iteration 2, loss = 0.24268728\n",
      "Iteration 3, loss = 0.18723117\n",
      "Iteration 4, loss = 0.15122385\n",
      "Iteration 5, loss = 0.12457541\n",
      "Iteration 6, loss = 0.10350009\n",
      "Iteration 7, loss = 0.08748259\n",
      "Iteration 8, loss = 0.07668430\n",
      "Iteration 9, loss = 0.06574267\n",
      "Iteration 10, loss = 0.05651468\n",
      "Iteration 1, loss = 0.49058776\n",
      "Iteration 2, loss = 0.23376633\n",
      "Iteration 3, loss = 0.17466378\n",
      "Iteration 4, loss = 0.15225649\n",
      "Iteration 5, loss = 0.13894194\n",
      "Iteration 6, loss = 0.10032304\n",
      "Iteration 7, loss = 0.08324941\n",
      "Iteration 8, loss = 0.07771976\n",
      "Iteration 9, loss = 0.06221063\n",
      "Iteration 10, loss = 0.05579268\n",
      "Iteration 1, loss = 0.50599556\n",
      "Iteration 2, loss = 0.23863333\n",
      "Iteration 3, loss = 0.18214889\n",
      "Iteration 4, loss = 0.14587668\n",
      "Iteration 5, loss = 0.12118906\n",
      "Iteration 6, loss = 0.10179355\n",
      "Iteration 7, loss = 0.08626492\n",
      "Iteration 8, loss = 0.07634892\n",
      "Iteration 9, loss = 0.06544944\n",
      "Iteration 10, loss = 0.05483956\n",
      "Iteration 1, loss = 0.49776709\n",
      "Iteration 2, loss = 0.24268728\n",
      "Iteration 3, loss = 0.18723117\n",
      "Iteration 4, loss = 0.15122385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.12457541\n",
      "Iteration 6, loss = 0.10350009\n",
      "Iteration 7, loss = 0.08748259\n",
      "Iteration 8, loss = 0.07668430\n",
      "Iteration 9, loss = 0.06574267\n",
      "Iteration 10, loss = 0.05651468\n",
      "Iteration 1, loss = 0.49058776\n",
      "Iteration 2, loss = 0.23376633\n",
      "Iteration 3, loss = 0.17466378\n",
      "Iteration 4, loss = 0.15225649\n",
      "Iteration 5, loss = 0.13894194\n",
      "Iteration 6, loss = 0.10032304\n",
      "Iteration 7, loss = 0.08324941\n",
      "Iteration 8, loss = 0.07771976\n",
      "Iteration 9, loss = 0.06221063\n",
      "Iteration 10, loss = 0.05579268\n",
      "Iteration 1, loss = 2.34260015\n",
      "Iteration 2, loss = 2.14886463\n",
      "Iteration 3, loss = 2.09475263\n",
      "Iteration 4, loss = 2.10229481\n",
      "Iteration 5, loss = 2.11440993\n",
      "Iteration 6, loss = 2.11748273\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.18185742\n",
      "Iteration 2, loss = 2.02238859\n",
      "Iteration 3, loss = 1.88130254\n",
      "Iteration 4, loss = 1.93908303\n",
      "Iteration 5, loss = 1.97785277\n",
      "Iteration 6, loss = 2.00253985\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.97227245\n",
      "Iteration 2, loss = 2.36351772\n",
      "Iteration 3, loss = 2.36199730\n",
      "Iteration 4, loss = 2.35989162\n",
      "Iteration 5, loss = 2.35954783\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.34260015\n",
      "Iteration 2, loss = 2.14886463\n",
      "Iteration 3, loss = 2.09475263\n",
      "Iteration 4, loss = 2.10229481\n",
      "Iteration 5, loss = 2.11440993\n",
      "Iteration 6, loss = 2.11748273\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.18185742\n",
      "Iteration 2, loss = 2.02238859\n",
      "Iteration 3, loss = 1.88130254\n",
      "Iteration 4, loss = 1.93908303\n",
      "Iteration 5, loss = 1.97785277\n",
      "Iteration 6, loss = 2.00253985\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.97227245\n",
      "Iteration 2, loss = 2.36351772\n",
      "Iteration 3, loss = 2.36199730\n",
      "Iteration 4, loss = 2.35989162\n",
      "Iteration 5, loss = 2.35954783\n",
      "Iteration 6, loss = 2.36004850\n",
      "Iteration 7, loss = 2.36053127\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.53695208\n",
      "Iteration 2, loss = 0.25825986\n",
      "Iteration 3, loss = 0.20772753\n",
      "Iteration 4, loss = 0.17728622\n",
      "Iteration 5, loss = 0.15360470\n",
      "Iteration 6, loss = 0.13947020\n",
      "Iteration 7, loss = 0.12655701\n",
      "Iteration 8, loss = 0.11772564\n",
      "Iteration 9, loss = 0.10486691\n",
      "Iteration 10, loss = 0.09623685\n",
      "Iteration 1, loss = 0.53281002\n",
      "Iteration 2, loss = 0.25866251\n",
      "Iteration 3, loss = 0.20826052\n",
      "Iteration 4, loss = 0.17454317\n",
      "Iteration 5, loss = 0.15126524\n",
      "Iteration 6, loss = 0.13344943\n",
      "Iteration 7, loss = 0.12083509\n",
      "Iteration 8, loss = 0.10844875\n",
      "Iteration 9, loss = 0.09794414\n",
      "Iteration 10, loss = 0.08692843\n",
      "Iteration 1, loss = 0.53139858\n",
      "Iteration 2, loss = 0.25260228\n",
      "Iteration 3, loss = 0.20332446\n",
      "Iteration 4, loss = 0.26054551\n",
      "Iteration 5, loss = 0.15742678\n",
      "Iteration 6, loss = 0.13507657\n",
      "Iteration 7, loss = 0.11951732\n",
      "Iteration 8, loss = 0.10793472\n",
      "Iteration 9, loss = 0.11183460\n",
      "Iteration 10, loss = 0.08737538\n",
      "Iteration 1, loss = 0.53695208\n",
      "Iteration 2, loss = 0.25825986\n",
      "Iteration 3, loss = 0.20772753\n",
      "Iteration 4, loss = 0.17728622\n",
      "Iteration 5, loss = 0.15360470\n",
      "Iteration 6, loss = 0.13947020\n",
      "Iteration 7, loss = 0.12655701\n",
      "Iteration 8, loss = 0.11772564\n",
      "Iteration 9, loss = 0.10486691\n",
      "Iteration 10, loss = 0.09623685\n",
      "Iteration 1, loss = 0.53281002\n",
      "Iteration 2, loss = 0.25866251\n",
      "Iteration 3, loss = 0.20826052\n",
      "Iteration 4, loss = 0.17454317\n",
      "Iteration 5, loss = 0.15126524\n",
      "Iteration 6, loss = 0.13344943\n",
      "Iteration 7, loss = 0.12083509\n",
      "Iteration 8, loss = 0.10844875\n",
      "Iteration 9, loss = 0.09794414\n",
      "Iteration 10, loss = 0.08692843\n",
      "Iteration 1, loss = 0.53139858\n",
      "Iteration 2, loss = 0.25260228\n",
      "Iteration 3, loss = 0.20332446\n",
      "Iteration 4, loss = 0.26054551\n",
      "Iteration 5, loss = 0.15742678\n",
      "Iteration 6, loss = 0.13507657\n",
      "Iteration 7, loss = 0.11951732\n",
      "Iteration 8, loss = 0.10793472\n",
      "Iteration 9, loss = 0.11183460\n",
      "Iteration 10, loss = 0.08737538\n",
      "Iteration 1, loss = 2.21989565\n",
      "Iteration 2, loss = 2.00487077\n",
      "Iteration 3, loss = 2.01204842\n",
      "Iteration 4, loss = 2.01914811\n",
      "Iteration 5, loss = 1.99818281\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.43467634\n",
      "Iteration 2, loss = 2.29333744\n",
      "Iteration 3, loss = 2.31667779\n",
      "Iteration 4, loss = 2.31396308\n",
      "Iteration 5, loss = 2.31361523\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.13310501\n",
      "Iteration 2, loss = 1.96055013\n",
      "Iteration 3, loss = 1.84948576\n",
      "Iteration 4, loss = 1.84061516\n",
      "Iteration 5, loss = 2.03487782\n",
      "Iteration 6, loss = 2.02805751\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.21989565\n",
      "Iteration 2, loss = 2.00487077\n",
      "Iteration 3, loss = 2.01204842\n",
      "Iteration 4, loss = 2.01914811\n",
      "Iteration 5, loss = 1.99818281\n",
      "Iteration 6, loss = 1.98927647\n",
      "Iteration 7, loss = 1.98560550\n",
      "Iteration 8, loss = 1.98292422\n",
      "Iteration 9, loss = 2.00306895\n",
      "Iteration 10, loss = 1.98352118\n",
      "Iteration 1, loss = 2.43467634\n",
      "Iteration 2, loss = 2.29333744\n",
      "Iteration 3, loss = 2.31667779\n",
      "Iteration 4, loss = 2.31396308\n",
      "Iteration 5, loss = 2.31361523\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.13310501\n",
      "Iteration 2, loss = 1.96055013\n",
      "Iteration 3, loss = 1.84948576\n",
      "Iteration 4, loss = 1.84061516\n",
      "Iteration 5, loss = 2.03487782\n",
      "Iteration 6, loss = 2.02805751\n",
      "Iteration 7, loss = 2.00818991\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.51894432\n",
      "Iteration 2, loss = 0.24614525\n",
      "Iteration 3, loss = 0.19337445\n",
      "Iteration 4, loss = 0.15705643\n",
      "Iteration 5, loss = 0.13010558\n",
      "Iteration 6, loss = 0.11287046\n",
      "Iteration 7, loss = 0.09522054\n",
      "Iteration 8, loss = 0.08346734\n",
      "Iteration 9, loss = 0.07449011\n",
      "Iteration 10, loss = 0.06684617\n",
      "Iteration 1, loss = 0.52261172\n",
      "Iteration 2, loss = 0.24268585\n",
      "Iteration 3, loss = 0.18905108\n",
      "Iteration 4, loss = 0.15554858\n",
      "Iteration 5, loss = 0.13135969\n",
      "Iteration 6, loss = 0.11355115\n",
      "Iteration 7, loss = 0.09644722\n",
      "Iteration 8, loss = 0.08392423\n",
      "Iteration 9, loss = 0.07303382\n",
      "Iteration 10, loss = 0.06393290\n",
      "Iteration 1, loss = 0.52459440\n",
      "Iteration 2, loss = 0.24166603\n",
      "Iteration 3, loss = 0.18620071\n",
      "Iteration 4, loss = 0.15008212\n",
      "Iteration 5, loss = 0.12376611\n",
      "Iteration 6, loss = 0.12078958\n",
      "Iteration 7, loss = 0.09637790\n",
      "Iteration 8, loss = 0.08101470\n",
      "Iteration 9, loss = 0.10801892\n",
      "Iteration 10, loss = 0.11200647\n",
      "Iteration 1, loss = 0.51894432\n",
      "Iteration 2, loss = 0.24614525\n",
      "Iteration 3, loss = 0.19337445\n",
      "Iteration 4, loss = 0.15705643\n",
      "Iteration 5, loss = 0.13010558\n",
      "Iteration 6, loss = 0.11287046\n",
      "Iteration 7, loss = 0.09522054\n",
      "Iteration 8, loss = 0.08346734\n",
      "Iteration 9, loss = 0.07449011\n",
      "Iteration 10, loss = 0.06684617\n",
      "Iteration 1, loss = 0.52261172\n",
      "Iteration 2, loss = 0.24268585\n",
      "Iteration 3, loss = 0.18905108\n",
      "Iteration 4, loss = 0.15554858\n",
      "Iteration 5, loss = 0.13135969\n",
      "Iteration 6, loss = 0.11355115\n",
      "Iteration 7, loss = 0.09644722\n",
      "Iteration 8, loss = 0.08392423\n",
      "Iteration 9, loss = 0.07303382\n",
      "Iteration 10, loss = 0.06393290\n",
      "Iteration 1, loss = 0.52459440\n",
      "Iteration 2, loss = 0.24166603\n",
      "Iteration 3, loss = 0.18620071\n",
      "Iteration 4, loss = 0.15008212\n",
      "Iteration 5, loss = 0.12376611\n",
      "Iteration 6, loss = 0.12078958\n",
      "Iteration 7, loss = 0.09637790\n",
      "Iteration 8, loss = 0.08101470\n",
      "Iteration 9, loss = 0.10801892\n",
      "Iteration 10, loss = 0.11200647\n",
      "Iteration 1, loss = 1.87127182\n",
      "Iteration 2, loss = 1.62047412\n",
      "Iteration 3, loss = 1.81158201\n",
      "Iteration 4, loss = 1.97562672\n",
      "Iteration 5, loss = 1.99099006\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.95757590\n",
      "Iteration 2, loss = 1.86309499\n",
      "Iteration 3, loss = 1.99902641\n",
      "Iteration 4, loss = 1.98304667\n",
      "Iteration 5, loss = 1.92224295\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.15750298\n",
      "Iteration 2, loss = 1.95112950\n",
      "Iteration 3, loss = 2.02214689\n",
      "Iteration 4, loss = 2.00088135\n",
      "Iteration 5, loss = 1.99149022\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.87127182\n",
      "Iteration 2, loss = 1.62047412\n",
      "Iteration 3, loss = 1.81158201\n",
      "Iteration 4, loss = 1.97562672\n",
      "Iteration 5, loss = 1.99099006\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.95757590\n",
      "Iteration 2, loss = 1.86309499\n",
      "Iteration 3, loss = 1.99902641\n",
      "Iteration 4, loss = 1.98304667\n",
      "Iteration 5, loss = 1.92224295\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.15750298\n",
      "Iteration 2, loss = 1.95112950\n",
      "Iteration 3, loss = 2.02214689\n",
      "Iteration 4, loss = 2.00088135\n",
      "Iteration 5, loss = 1.99149022\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.50599556\n",
      "Iteration 2, loss = 0.23863333\n",
      "Iteration 3, loss = 0.18214889\n",
      "Iteration 4, loss = 0.14587668\n",
      "Iteration 5, loss = 0.12118906\n",
      "Iteration 6, loss = 0.10179355\n",
      "Iteration 7, loss = 0.08626492\n",
      "Iteration 8, loss = 0.07634892\n",
      "Iteration 9, loss = 0.06544944\n",
      "Iteration 10, loss = 0.05483956\n",
      "Iteration 1, loss = 0.49776709\n",
      "Iteration 2, loss = 0.24268728\n",
      "Iteration 3, loss = 0.18723117\n",
      "Iteration 4, loss = 0.15122385\n",
      "Iteration 5, loss = 0.12457541\n",
      "Iteration 6, loss = 0.10350009\n",
      "Iteration 7, loss = 0.08748259\n",
      "Iteration 8, loss = 0.07668430\n",
      "Iteration 9, loss = 0.06574267\n",
      "Iteration 10, loss = 0.05651468\n",
      "Iteration 1, loss = 0.49058776\n",
      "Iteration 2, loss = 0.23376633\n",
      "Iteration 3, loss = 0.17466378\n",
      "Iteration 4, loss = 0.15225649\n",
      "Iteration 5, loss = 0.13894194\n",
      "Iteration 6, loss = 0.10032304\n",
      "Iteration 7, loss = 0.08324941\n",
      "Iteration 8, loss = 0.07771976\n",
      "Iteration 9, loss = 0.06221063\n",
      "Iteration 10, loss = 0.05579268\n",
      "Iteration 1, loss = 0.50599556\n",
      "Iteration 2, loss = 0.23863333\n",
      "Iteration 3, loss = 0.18214889\n",
      "Iteration 4, loss = 0.14587668\n",
      "Iteration 5, loss = 0.12118906\n",
      "Iteration 6, loss = 0.10179355\n",
      "Iteration 7, loss = 0.08626492\n",
      "Iteration 8, loss = 0.07634892\n",
      "Iteration 9, loss = 0.06544944\n",
      "Iteration 10, loss = 0.05483956\n",
      "Iteration 1, loss = 0.49776709\n",
      "Iteration 2, loss = 0.24268728\n",
      "Iteration 3, loss = 0.18723117\n",
      "Iteration 4, loss = 0.15122385\n",
      "Iteration 5, loss = 0.12457541\n",
      "Iteration 6, loss = 0.10350009\n",
      "Iteration 7, loss = 0.08748259\n",
      "Iteration 8, loss = 0.07668430\n",
      "Iteration 9, loss = 0.06574267\n",
      "Iteration 10, loss = 0.05651468\n",
      "Iteration 1, loss = 0.49058776\n",
      "Iteration 2, loss = 0.23376633\n",
      "Iteration 3, loss = 0.17466378\n",
      "Iteration 4, loss = 0.15225649\n",
      "Iteration 5, loss = 0.13894194\n",
      "Iteration 6, loss = 0.10032304\n",
      "Iteration 7, loss = 0.08324941\n",
      "Iteration 8, loss = 0.07771976\n",
      "Iteration 9, loss = 0.06221063\n",
      "Iteration 10, loss = 0.05579268\n",
      "Iteration 1, loss = 2.34260015\n",
      "Iteration 2, loss = 2.14886463\n",
      "Iteration 3, loss = 2.09475263\n",
      "Iteration 4, loss = 2.10229481\n",
      "Iteration 5, loss = 2.11440993\n",
      "Iteration 6, loss = 2.11748273\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.18185742\n",
      "Iteration 2, loss = 2.02238859\n",
      "Iteration 3, loss = 1.88130254\n",
      "Iteration 4, loss = 1.93908303\n",
      "Iteration 5, loss = 1.97785277\n",
      "Iteration 6, loss = 2.00253985\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.97227245\n",
      "Iteration 2, loss = 2.36351772\n",
      "Iteration 3, loss = 2.36199730\n",
      "Iteration 4, loss = 2.35989162\n",
      "Iteration 5, loss = 2.35954783\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.34260015\n",
      "Iteration 2, loss = 2.14886463\n",
      "Iteration 3, loss = 2.09475263\n",
      "Iteration 4, loss = 2.10229481\n",
      "Iteration 5, loss = 2.11440993\n",
      "Iteration 6, loss = 2.11748273\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.18185742\n",
      "Iteration 2, loss = 2.02238859\n",
      "Iteration 3, loss = 1.88130254\n",
      "Iteration 4, loss = 1.93908303\n",
      "Iteration 5, loss = 1.97785277\n",
      "Iteration 6, loss = 2.00253985\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.97227245\n",
      "Iteration 2, loss = 2.36351772\n",
      "Iteration 3, loss = 2.36199730\n",
      "Iteration 4, loss = 2.35989162\n",
      "Iteration 5, loss = 2.35954783\n",
      "Iteration 6, loss = 2.36004850\n",
      "Iteration 7, loss = 2.36053127\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.53695208\n",
      "Iteration 2, loss = 0.25825986\n",
      "Iteration 3, loss = 0.20772753\n",
      "Iteration 4, loss = 0.17728622\n",
      "Iteration 5, loss = 0.15360470\n",
      "Iteration 6, loss = 0.13947020\n",
      "Iteration 7, loss = 0.12655701\n",
      "Iteration 8, loss = 0.11772564\n",
      "Iteration 9, loss = 0.10486691\n",
      "Iteration 10, loss = 0.09623685\n",
      "Iteration 1, loss = 0.53281002\n",
      "Iteration 2, loss = 0.25866251\n",
      "Iteration 3, loss = 0.20826052\n",
      "Iteration 4, loss = 0.17454317\n",
      "Iteration 5, loss = 0.15126524\n",
      "Iteration 6, loss = 0.13344943\n",
      "Iteration 7, loss = 0.12083509\n",
      "Iteration 8, loss = 0.10844875\n",
      "Iteration 9, loss = 0.09794414\n",
      "Iteration 10, loss = 0.08692843\n",
      "Iteration 1, loss = 0.53139858\n",
      "Iteration 2, loss = 0.25260228\n",
      "Iteration 3, loss = 0.20332446\n",
      "Iteration 4, loss = 0.26054551\n",
      "Iteration 5, loss = 0.15742678\n",
      "Iteration 6, loss = 0.13507657\n",
      "Iteration 7, loss = 0.11951732\n",
      "Iteration 8, loss = 0.10793472\n",
      "Iteration 9, loss = 0.11183460\n",
      "Iteration 10, loss = 0.08737538\n",
      "Iteration 1, loss = 0.53695208\n",
      "Iteration 2, loss = 0.25825986\n",
      "Iteration 3, loss = 0.20772753\n",
      "Iteration 4, loss = 0.17728622\n",
      "Iteration 5, loss = 0.15360470\n",
      "Iteration 6, loss = 0.13947020\n",
      "Iteration 7, loss = 0.12655701\n",
      "Iteration 8, loss = 0.11772564\n",
      "Iteration 9, loss = 0.10486691\n",
      "Iteration 10, loss = 0.09623685\n",
      "Iteration 1, loss = 0.53281002\n",
      "Iteration 2, loss = 0.25866251\n",
      "Iteration 3, loss = 0.20826052\n",
      "Iteration 4, loss = 0.17454317\n",
      "Iteration 5, loss = 0.15126524\n",
      "Iteration 6, loss = 0.13344943\n",
      "Iteration 7, loss = 0.12083509\n",
      "Iteration 8, loss = 0.10844875\n",
      "Iteration 9, loss = 0.09794414\n",
      "Iteration 10, loss = 0.08692843\n",
      "Iteration 1, loss = 0.53139858\n",
      "Iteration 2, loss = 0.25260228\n",
      "Iteration 3, loss = 0.20332446\n",
      "Iteration 4, loss = 0.26054551\n",
      "Iteration 5, loss = 0.15742678\n",
      "Iteration 6, loss = 0.13507657\n",
      "Iteration 7, loss = 0.11951732\n",
      "Iteration 8, loss = 0.10793472\n",
      "Iteration 9, loss = 0.11183460\n",
      "Iteration 10, loss = 0.08737538\n",
      "Iteration 1, loss = 2.21989565\n",
      "Iteration 2, loss = 2.00487077\n",
      "Iteration 3, loss = 2.01204842\n",
      "Iteration 4, loss = 2.01914811\n",
      "Iteration 5, loss = 1.99818281\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.43467634\n",
      "Iteration 2, loss = 2.29333744\n",
      "Iteration 3, loss = 2.31667779\n",
      "Iteration 4, loss = 2.31396308\n",
      "Iteration 5, loss = 2.31361523\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.13310501\n",
      "Iteration 2, loss = 1.96055013\n",
      "Iteration 3, loss = 1.84948576\n",
      "Iteration 4, loss = 1.84061516\n",
      "Iteration 5, loss = 2.03487782\n",
      "Iteration 6, loss = 2.02805751\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.21989565\n",
      "Iteration 2, loss = 2.00487077\n",
      "Iteration 3, loss = 2.01204842\n",
      "Iteration 4, loss = 2.01914811\n",
      "Iteration 5, loss = 1.99818281\n",
      "Iteration 6, loss = 1.98927647\n",
      "Iteration 7, loss = 1.98560550\n",
      "Iteration 8, loss = 1.98292422\n",
      "Iteration 9, loss = 2.00306895\n",
      "Iteration 10, loss = 1.98352118\n",
      "Iteration 1, loss = 2.43467634\n",
      "Iteration 2, loss = 2.29333744\n",
      "Iteration 3, loss = 2.31667779\n",
      "Iteration 4, loss = 2.31396308\n",
      "Iteration 5, loss = 2.31361523\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.13310501\n",
      "Iteration 2, loss = 1.96055013\n",
      "Iteration 3, loss = 1.84948576\n",
      "Iteration 4, loss = 1.84061516\n",
      "Iteration 5, loss = 2.03487782\n",
      "Iteration 6, loss = 2.02805751\n",
      "Iteration 7, loss = 2.00818991\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.51894432\n",
      "Iteration 2, loss = 0.24614525\n",
      "Iteration 3, loss = 0.19337445\n",
      "Iteration 4, loss = 0.15705643\n",
      "Iteration 5, loss = 0.13010558\n",
      "Iteration 6, loss = 0.11287046\n",
      "Iteration 7, loss = 0.09522054\n",
      "Iteration 8, loss = 0.08346734\n",
      "Iteration 9, loss = 0.07449011\n",
      "Iteration 10, loss = 0.06684617\n",
      "Iteration 1, loss = 0.52261172\n",
      "Iteration 2, loss = 0.24268585\n",
      "Iteration 3, loss = 0.18905108\n",
      "Iteration 4, loss = 0.15554858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.13135969\n",
      "Iteration 6, loss = 0.11355115\n",
      "Iteration 7, loss = 0.09644722\n",
      "Iteration 8, loss = 0.08392423\n",
      "Iteration 9, loss = 0.07303382\n",
      "Iteration 10, loss = 0.06393290\n",
      "Iteration 1, loss = 0.52459440\n",
      "Iteration 2, loss = 0.24166603\n",
      "Iteration 3, loss = 0.18620071\n",
      "Iteration 4, loss = 0.15008212\n",
      "Iteration 5, loss = 0.12376611\n",
      "Iteration 6, loss = 0.12078958\n",
      "Iteration 7, loss = 0.09637790\n",
      "Iteration 8, loss = 0.08101470\n",
      "Iteration 9, loss = 0.10801892\n",
      "Iteration 10, loss = 0.11200647\n",
      "Iteration 1, loss = 0.51894432\n",
      "Iteration 2, loss = 0.24614525\n",
      "Iteration 3, loss = 0.19337445\n",
      "Iteration 4, loss = 0.15705643\n",
      "Iteration 5, loss = 0.13010558\n",
      "Iteration 6, loss = 0.11287046\n",
      "Iteration 7, loss = 0.09522054\n",
      "Iteration 8, loss = 0.08346734\n",
      "Iteration 9, loss = 0.07449011\n",
      "Iteration 10, loss = 0.06684617\n",
      "Iteration 1, loss = 0.52261172\n",
      "Iteration 2, loss = 0.24268585\n",
      "Iteration 3, loss = 0.18905108\n",
      "Iteration 4, loss = 0.15554858\n",
      "Iteration 5, loss = 0.13135969\n",
      "Iteration 6, loss = 0.11355115\n",
      "Iteration 7, loss = 0.09644722\n",
      "Iteration 8, loss = 0.08392423\n",
      "Iteration 9, loss = 0.07303382\n",
      "Iteration 10, loss = 0.06393290\n",
      "Iteration 1, loss = 0.52459440\n",
      "Iteration 2, loss = 0.24166603\n",
      "Iteration 3, loss = 0.18620071\n",
      "Iteration 4, loss = 0.15008212\n",
      "Iteration 5, loss = 0.12376611\n",
      "Iteration 6, loss = 0.12078958\n",
      "Iteration 7, loss = 0.09637790\n",
      "Iteration 8, loss = 0.08101470\n",
      "Iteration 9, loss = 0.10801892\n",
      "Iteration 10, loss = 0.11200647\n",
      "Iteration 1, loss = 1.87127182\n",
      "Iteration 2, loss = 1.62047412\n",
      "Iteration 3, loss = 1.81158201\n",
      "Iteration 4, loss = 1.97562672\n",
      "Iteration 5, loss = 1.99099006\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.95757590\n",
      "Iteration 2, loss = 1.86309499\n",
      "Iteration 3, loss = 1.99902641\n",
      "Iteration 4, loss = 1.98304667\n",
      "Iteration 5, loss = 1.92224295\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.15750298\n",
      "Iteration 2, loss = 1.95112950\n",
      "Iteration 3, loss = 2.02214689\n",
      "Iteration 4, loss = 2.00088135\n",
      "Iteration 5, loss = 1.99149022\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.87127182\n",
      "Iteration 2, loss = 1.62047412\n",
      "Iteration 3, loss = 1.81158201\n",
      "Iteration 4, loss = 1.97562672\n",
      "Iteration 5, loss = 1.99099006\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.95757590\n",
      "Iteration 2, loss = 1.86309499\n",
      "Iteration 3, loss = 1.99902641\n",
      "Iteration 4, loss = 1.98304667\n",
      "Iteration 5, loss = 1.92224295\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.15750298\n",
      "Iteration 2, loss = 1.95112950\n",
      "Iteration 3, loss = 2.02214689\n",
      "Iteration 4, loss = 2.00088135\n",
      "Iteration 5, loss = 1.99149022\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.50599556\n",
      "Iteration 2, loss = 0.23863333\n",
      "Iteration 3, loss = 0.18214889\n",
      "Iteration 4, loss = 0.14587668\n",
      "Iteration 5, loss = 0.12118906\n",
      "Iteration 6, loss = 0.10179355\n",
      "Iteration 7, loss = 0.08626492\n",
      "Iteration 8, loss = 0.07634892\n",
      "Iteration 9, loss = 0.06544944\n",
      "Iteration 10, loss = 0.05483956\n",
      "Iteration 1, loss = 0.49776709\n",
      "Iteration 2, loss = 0.24268728\n",
      "Iteration 3, loss = 0.18723117\n",
      "Iteration 4, loss = 0.15122385\n",
      "Iteration 5, loss = 0.12457541\n",
      "Iteration 6, loss = 0.10350009\n",
      "Iteration 7, loss = 0.08748259\n",
      "Iteration 8, loss = 0.07668430\n",
      "Iteration 9, loss = 0.06574267\n",
      "Iteration 10, loss = 0.05651468\n",
      "Iteration 1, loss = 0.49058776\n",
      "Iteration 2, loss = 0.23376633\n",
      "Iteration 3, loss = 0.17466378\n",
      "Iteration 4, loss = 0.15225649\n",
      "Iteration 5, loss = 0.13894194\n",
      "Iteration 6, loss = 0.10032304\n",
      "Iteration 7, loss = 0.08324941\n",
      "Iteration 8, loss = 0.07771976\n",
      "Iteration 9, loss = 0.06221063\n",
      "Iteration 10, loss = 0.05579268\n",
      "Iteration 1, loss = 0.50599556\n",
      "Iteration 2, loss = 0.23863333\n",
      "Iteration 3, loss = 0.18214889\n",
      "Iteration 4, loss = 0.14587668\n",
      "Iteration 5, loss = 0.12118906\n",
      "Iteration 6, loss = 0.10179355\n",
      "Iteration 7, loss = 0.08626492\n",
      "Iteration 8, loss = 0.07634892\n",
      "Iteration 9, loss = 0.06544944\n",
      "Iteration 10, loss = 0.05483956\n",
      "Iteration 1, loss = 0.49776709\n",
      "Iteration 2, loss = 0.24268728\n",
      "Iteration 3, loss = 0.18723117\n",
      "Iteration 4, loss = 0.15122385\n",
      "Iteration 5, loss = 0.12457541\n",
      "Iteration 6, loss = 0.10350009\n",
      "Iteration 7, loss = 0.08748259\n",
      "Iteration 8, loss = 0.07668430\n",
      "Iteration 9, loss = 0.06574267\n",
      "Iteration 10, loss = 0.05651468\n",
      "Iteration 1, loss = 0.49058776\n",
      "Iteration 2, loss = 0.23376633\n",
      "Iteration 3, loss = 0.17466378\n",
      "Iteration 4, loss = 0.15225649\n",
      "Iteration 5, loss = 0.13894194\n",
      "Iteration 6, loss = 0.10032304\n",
      "Iteration 7, loss = 0.08324941\n",
      "Iteration 8, loss = 0.07771976\n",
      "Iteration 9, loss = 0.06221063\n",
      "Iteration 10, loss = 0.05579268\n",
      "Iteration 1, loss = 2.34260015\n",
      "Iteration 2, loss = 2.14886463\n",
      "Iteration 3, loss = 2.09475263\n",
      "Iteration 4, loss = 2.10229481\n",
      "Iteration 5, loss = 2.11440993\n",
      "Iteration 6, loss = 2.11748273\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.18185742\n",
      "Iteration 2, loss = 2.02238859\n",
      "Iteration 3, loss = 1.88130254\n",
      "Iteration 4, loss = 1.93908303\n",
      "Iteration 5, loss = 1.97785277\n",
      "Iteration 6, loss = 2.00253985\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.97227245\n",
      "Iteration 2, loss = 2.36351772\n",
      "Iteration 3, loss = 2.36199730\n",
      "Iteration 4, loss = 2.35989162\n",
      "Iteration 5, loss = 2.35954783\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.34260015\n",
      "Iteration 2, loss = 2.14886463\n",
      "Iteration 3, loss = 2.09475263\n",
      "Iteration 4, loss = 2.10229481\n",
      "Iteration 5, loss = 2.11440993\n",
      "Iteration 6, loss = 2.11748273\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.18185742\n",
      "Iteration 2, loss = 2.02238859\n",
      "Iteration 3, loss = 1.88130254\n",
      "Iteration 4, loss = 1.93908303\n",
      "Iteration 5, loss = 1.97785277\n",
      "Iteration 6, loss = 2.00253985\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.97227245\n",
      "Iteration 2, loss = 2.36351772\n",
      "Iteration 3, loss = 2.36199730\n",
      "Iteration 4, loss = 2.35989162\n",
      "Iteration 5, loss = 2.35954783\n",
      "Iteration 6, loss = 2.36004850\n",
      "Iteration 7, loss = 2.36053127\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.53695208\n",
      "Iteration 2, loss = 0.25825986\n",
      "Iteration 3, loss = 0.20772753\n",
      "Iteration 4, loss = 0.17728622\n",
      "Iteration 5, loss = 0.15360470\n",
      "Iteration 6, loss = 0.13947020\n",
      "Iteration 7, loss = 0.12655701\n",
      "Iteration 8, loss = 0.11772564\n",
      "Iteration 9, loss = 0.10486691\n",
      "Iteration 10, loss = 0.09623685\n",
      "Iteration 1, loss = 0.53281002\n",
      "Iteration 2, loss = 0.25866251\n",
      "Iteration 3, loss = 0.20826052\n",
      "Iteration 4, loss = 0.17454317\n",
      "Iteration 5, loss = 0.15126524\n",
      "Iteration 6, loss = 0.13344943\n",
      "Iteration 7, loss = 0.12083509\n",
      "Iteration 8, loss = 0.10844875\n",
      "Iteration 9, loss = 0.09794414\n",
      "Iteration 10, loss = 0.08692843\n",
      "Iteration 1, loss = 0.53139858\n",
      "Iteration 2, loss = 0.25260228\n",
      "Iteration 3, loss = 0.20332446\n",
      "Iteration 4, loss = 0.26054551\n",
      "Iteration 5, loss = 0.15742678\n",
      "Iteration 6, loss = 0.13507657\n",
      "Iteration 7, loss = 0.11951732\n",
      "Iteration 8, loss = 0.10793472\n",
      "Iteration 9, loss = 0.11183460\n",
      "Iteration 10, loss = 0.08737538\n",
      "Iteration 1, loss = 0.53695208\n",
      "Iteration 2, loss = 0.25825986\n",
      "Iteration 3, loss = 0.20772753\n",
      "Iteration 4, loss = 0.17728622\n",
      "Iteration 5, loss = 0.15360470\n",
      "Iteration 6, loss = 0.13947020\n",
      "Iteration 7, loss = 0.12655701\n",
      "Iteration 8, loss = 0.11772564\n",
      "Iteration 9, loss = 0.10486691\n",
      "Iteration 10, loss = 0.09623685\n",
      "Iteration 1, loss = 0.53281002\n",
      "Iteration 2, loss = 0.25866251\n",
      "Iteration 3, loss = 0.20826052\n",
      "Iteration 4, loss = 0.17454317\n",
      "Iteration 5, loss = 0.15126524\n",
      "Iteration 6, loss = 0.13344943\n",
      "Iteration 7, loss = 0.12083509\n",
      "Iteration 8, loss = 0.10844875\n",
      "Iteration 9, loss = 0.09794414\n",
      "Iteration 10, loss = 0.08692843\n",
      "Iteration 1, loss = 0.53139858\n",
      "Iteration 2, loss = 0.25260228\n",
      "Iteration 3, loss = 0.20332446\n",
      "Iteration 4, loss = 0.26054551\n",
      "Iteration 5, loss = 0.15742678\n",
      "Iteration 6, loss = 0.13507657\n",
      "Iteration 7, loss = 0.11951732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.10793472\n",
      "Iteration 9, loss = 0.11183460\n",
      "Iteration 10, loss = 0.08737538\n",
      "Iteration 1, loss = 2.21989565\n",
      "Iteration 2, loss = 2.00487077\n",
      "Iteration 3, loss = 2.01204842\n",
      "Iteration 4, loss = 2.01914811\n",
      "Iteration 5, loss = 1.99818281\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.43467634\n",
      "Iteration 2, loss = 2.29333744\n",
      "Iteration 3, loss = 2.31667779\n",
      "Iteration 4, loss = 2.31396308\n",
      "Iteration 5, loss = 2.31361523\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.13310501\n",
      "Iteration 2, loss = 1.96055013\n",
      "Iteration 3, loss = 1.84948576\n",
      "Iteration 4, loss = 1.84061516\n",
      "Iteration 5, loss = 2.03487782\n",
      "Iteration 6, loss = 2.02805751\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.21989565\n",
      "Iteration 2, loss = 2.00487077\n",
      "Iteration 3, loss = 2.01204842\n",
      "Iteration 4, loss = 2.01914811\n",
      "Iteration 5, loss = 1.99818281\n",
      "Iteration 6, loss = 1.98927647\n",
      "Iteration 7, loss = 1.98560550\n",
      "Iteration 8, loss = 1.98292422\n",
      "Iteration 9, loss = 2.00306895\n",
      "Iteration 10, loss = 1.98352118\n",
      "Iteration 1, loss = 2.43467634\n",
      "Iteration 2, loss = 2.29333744\n",
      "Iteration 3, loss = 2.31667779\n",
      "Iteration 4, loss = 2.31396308\n",
      "Iteration 5, loss = 2.31361523\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.13310501\n",
      "Iteration 2, loss = 1.96055013\n",
      "Iteration 3, loss = 1.84948576\n",
      "Iteration 4, loss = 1.84061516\n",
      "Iteration 5, loss = 2.03487782\n",
      "Iteration 6, loss = 2.02805751\n",
      "Iteration 7, loss = 2.00818991\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.51894432\n",
      "Iteration 2, loss = 0.24614525\n",
      "Iteration 3, loss = 0.19337445\n",
      "Iteration 4, loss = 0.15705643\n",
      "Iteration 5, loss = 0.13010558\n",
      "Iteration 6, loss = 0.11287046\n",
      "Iteration 7, loss = 0.09522054\n",
      "Iteration 8, loss = 0.08346734\n",
      "Iteration 9, loss = 0.07449011\n",
      "Iteration 10, loss = 0.06684617\n",
      "Iteration 1, loss = 0.52261172\n",
      "Iteration 2, loss = 0.24268585\n",
      "Iteration 3, loss = 0.18905108\n",
      "Iteration 4, loss = 0.15554858\n",
      "Iteration 5, loss = 0.13135969\n",
      "Iteration 6, loss = 0.11355115\n",
      "Iteration 7, loss = 0.09644722\n",
      "Iteration 8, loss = 0.08392423\n",
      "Iteration 9, loss = 0.07303382\n",
      "Iteration 10, loss = 0.06393290\n",
      "Iteration 1, loss = 0.52459440\n",
      "Iteration 2, loss = 0.24166603\n",
      "Iteration 3, loss = 0.18620071\n",
      "Iteration 4, loss = 0.15008212\n",
      "Iteration 5, loss = 0.12376611\n",
      "Iteration 6, loss = 0.12078958\n",
      "Iteration 7, loss = 0.09637790\n",
      "Iteration 8, loss = 0.08101470\n",
      "Iteration 9, loss = 0.10801892\n",
      "Iteration 10, loss = 0.11200647\n",
      "Iteration 1, loss = 0.51894432\n",
      "Iteration 2, loss = 0.24614525\n",
      "Iteration 3, loss = 0.19337445\n",
      "Iteration 4, loss = 0.15705643\n",
      "Iteration 5, loss = 0.13010558\n",
      "Iteration 6, loss = 0.11287046\n",
      "Iteration 7, loss = 0.09522054\n",
      "Iteration 8, loss = 0.08346734\n",
      "Iteration 9, loss = 0.07449011\n",
      "Iteration 10, loss = 0.06684617\n",
      "Iteration 1, loss = 0.52261172\n",
      "Iteration 2, loss = 0.24268585\n",
      "Iteration 3, loss = 0.18905108\n",
      "Iteration 4, loss = 0.15554858\n",
      "Iteration 5, loss = 0.13135969\n",
      "Iteration 6, loss = 0.11355115\n",
      "Iteration 7, loss = 0.09644722\n",
      "Iteration 8, loss = 0.08392423\n",
      "Iteration 9, loss = 0.07303382\n",
      "Iteration 10, loss = 0.06393290\n",
      "Iteration 1, loss = 0.52459440\n",
      "Iteration 2, loss = 0.24166603\n",
      "Iteration 3, loss = 0.18620071\n",
      "Iteration 4, loss = 0.15008212\n",
      "Iteration 5, loss = 0.12376611\n",
      "Iteration 6, loss = 0.12078958\n",
      "Iteration 7, loss = 0.09637790\n",
      "Iteration 8, loss = 0.08101470\n",
      "Iteration 9, loss = 0.10801892\n",
      "Iteration 10, loss = 0.11200647\n",
      "Iteration 1, loss = 1.87127182\n",
      "Iteration 2, loss = 1.62047412\n",
      "Iteration 3, loss = 1.81158201\n",
      "Iteration 4, loss = 1.97562672\n",
      "Iteration 5, loss = 1.99099006\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.95757590\n",
      "Iteration 2, loss = 1.86309499\n",
      "Iteration 3, loss = 1.99902641\n",
      "Iteration 4, loss = 1.98304667\n",
      "Iteration 5, loss = 1.92224295\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.15750298\n",
      "Iteration 2, loss = 1.95112950\n",
      "Iteration 3, loss = 2.02214689\n",
      "Iteration 4, loss = 2.00088135\n",
      "Iteration 5, loss = 1.99149022\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.87127182\n",
      "Iteration 2, loss = 1.62047412\n",
      "Iteration 3, loss = 1.81158201\n",
      "Iteration 4, loss = 1.97562672\n",
      "Iteration 5, loss = 1.99099006\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 1.95757590\n",
      "Iteration 2, loss = 1.86309499\n",
      "Iteration 3, loss = 1.99902641\n",
      "Iteration 4, loss = 1.98304667\n",
      "Iteration 5, loss = 1.92224295\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.15750298\n",
      "Iteration 2, loss = 1.95112950\n",
      "Iteration 3, loss = 2.02214689\n",
      "Iteration 4, loss = 2.00088135\n",
      "Iteration 5, loss = 1.99149022\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.50599556\n",
      "Iteration 2, loss = 0.23863333\n",
      "Iteration 3, loss = 0.18214889\n",
      "Iteration 4, loss = 0.14587668\n",
      "Iteration 5, loss = 0.12118906\n",
      "Iteration 6, loss = 0.10179355\n",
      "Iteration 7, loss = 0.08626492\n",
      "Iteration 8, loss = 0.07634892\n",
      "Iteration 9, loss = 0.06544944\n",
      "Iteration 10, loss = 0.05483956\n",
      "Iteration 1, loss = 0.49776709\n",
      "Iteration 2, loss = 0.24268728\n",
      "Iteration 3, loss = 0.18723117\n",
      "Iteration 4, loss = 0.15122385\n",
      "Iteration 5, loss = 0.12457541\n",
      "Iteration 6, loss = 0.10350009\n",
      "Iteration 7, loss = 0.08748259\n",
      "Iteration 8, loss = 0.07668430\n",
      "Iteration 9, loss = 0.06574267\n",
      "Iteration 10, loss = 0.05651468\n",
      "Iteration 1, loss = 0.49058776\n",
      "Iteration 2, loss = 0.23376633\n",
      "Iteration 3, loss = 0.17466378\n",
      "Iteration 4, loss = 0.15225649\n",
      "Iteration 5, loss = 0.13894194\n",
      "Iteration 6, loss = 0.10032304\n",
      "Iteration 7, loss = 0.08324941\n",
      "Iteration 8, loss = 0.07771976\n",
      "Iteration 9, loss = 0.06221063\n",
      "Iteration 10, loss = 0.05579268\n",
      "Iteration 1, loss = 0.50599556\n",
      "Iteration 2, loss = 0.23863333\n",
      "Iteration 3, loss = 0.18214889\n",
      "Iteration 4, loss = 0.14587668\n",
      "Iteration 5, loss = 0.12118906\n",
      "Iteration 6, loss = 0.10179355\n",
      "Iteration 7, loss = 0.08626492\n",
      "Iteration 8, loss = 0.07634892\n",
      "Iteration 9, loss = 0.06544944\n",
      "Iteration 10, loss = 0.05483956\n",
      "Iteration 1, loss = 0.49776709\n",
      "Iteration 2, loss = 0.24268728\n",
      "Iteration 3, loss = 0.18723117\n",
      "Iteration 4, loss = 0.15122385\n",
      "Iteration 5, loss = 0.12457541\n",
      "Iteration 6, loss = 0.10350009\n",
      "Iteration 7, loss = 0.08748259\n",
      "Iteration 8, loss = 0.07668430\n",
      "Iteration 9, loss = 0.06574267\n",
      "Iteration 10, loss = 0.05651468\n",
      "Iteration 1, loss = 0.49058776\n",
      "Iteration 2, loss = 0.23376633\n",
      "Iteration 3, loss = 0.17466378\n",
      "Iteration 4, loss = 0.15225649\n",
      "Iteration 5, loss = 0.13894194\n",
      "Iteration 6, loss = 0.10032304\n",
      "Iteration 7, loss = 0.08324941\n",
      "Iteration 8, loss = 0.07771976\n",
      "Iteration 9, loss = 0.06221063\n",
      "Iteration 10, loss = 0.05579268\n",
      "Iteration 1, loss = 2.34260015\n",
      "Iteration 2, loss = 2.14886463\n",
      "Iteration 3, loss = 2.09475263\n",
      "Iteration 4, loss = 2.10229481\n",
      "Iteration 5, loss = 2.11440993\n",
      "Iteration 6, loss = 2.11748273\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.18185742\n",
      "Iteration 2, loss = 2.02238859\n",
      "Iteration 3, loss = 1.88130254\n",
      "Iteration 4, loss = 1.93908303\n",
      "Iteration 5, loss = 1.97785277\n",
      "Iteration 6, loss = 2.00253985\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.97227245\n",
      "Iteration 2, loss = 2.36351772\n",
      "Iteration 3, loss = 2.36199730\n",
      "Iteration 4, loss = 2.35989162\n",
      "Iteration 5, loss = 2.35954783\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.34260015\n",
      "Iteration 2, loss = 2.14886463\n",
      "Iteration 3, loss = 2.09475263\n",
      "Iteration 4, loss = 2.10229481\n",
      "Iteration 5, loss = 2.11440993\n",
      "Iteration 6, loss = 2.11748273\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 2.18185742\n",
      "Iteration 2, loss = 2.02238859\n",
      "Iteration 3, loss = 1.88130254\n",
      "Iteration 4, loss = 1.93908303\n",
      "Iteration 5, loss = 1.97785277\n",
      "Iteration 6, loss = 2.00253985\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.97227245\n",
      "Iteration 2, loss = 2.36351772\n",
      "Iteration 3, loss = 2.36199730\n",
      "Iteration 4, loss = 2.35989162\n",
      "Iteration 5, loss = 2.35954783\n",
      "Iteration 6, loss = 2.36004850\n",
      "Iteration 7, loss = 2.36053127\n",
      "Training loss did not improve more than tol=0.001000 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.44212174\n",
      "Iteration 2, loss = 0.21545091\n",
      "Iteration 3, loss = 0.16297549\n",
      "Iteration 4, loss = 0.13209083\n",
      "Iteration 5, loss = 0.11104253\n",
      "Iteration 6, loss = 0.09782936\n",
      "Iteration 7, loss = 0.08488304\n",
      "Iteration 8, loss = 0.07522712\n",
      "Iteration 9, loss = 0.06585163\n",
      "Iteration 10, loss = 0.06023114\n",
      "Training loss did not improve more than tol=0.010000 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=[30], learning_rate='constant',\n",
       "       learning_rate_init=0.1, max_iter=10, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='sgd', tol=0.0001, validation_fraction=0.1, verbose=10,\n",
       "       warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'hidden_layer_sizes': [(30,), (40,), (50,)], 'learning_rate_init': [0.1, 1], 'tol': [0.01, 0.001], 'epsilon': [0.001, 1e-07, 1e-08, 1e-09]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98680000000000001"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.score(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96358333333333335"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epsilon': 0.001,\n",
       " 'hidden_layer_sizes': (40,),\n",
       " 'learning_rate_init': 0.1,\n",
       " 'tol': 0.01}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "pred = estimator.predict(test_x)\n",
    "accuracy_score(pred, test_y)\n",
    "a = confusion_matrix(pred, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.96      0.97      1219\n",
      "          1       0.99      0.97      0.98      1385\n",
      "          2       0.97      0.95      0.96      1180\n",
      "          3       0.96      0.97      0.96      1243\n",
      "          4       0.97      0.95      0.96      1161\n",
      "          5       0.95      0.95      0.95      1076\n",
      "          6       0.97      0.98      0.98      1156\n",
      "          7       0.97      0.97      0.97      1275\n",
      "          8       0.94      0.97      0.96      1146\n",
      "          9       0.92      0.96      0.94      1159\n",
      "\n",
      "avg / total       0.96      0.96      0.96     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
